{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMP24112 Summative Exercise: Air Quality Analysis (30 Marks)\n",
    "\n",
    "This lab exercise is about air quality analysis, where you will predict air quality through solving classification and regression tasks. You will submit a notebook file, a pdf report, and a trained model. You will be marked for implementation, design, result and analysis. Your code should be easy to read and your report should be concise (max 600 words). It is strongly recommended that you use a LaTeX editor, such as [Overleaf](https://www.overleaf.com/), to write your report.\n",
    "\n",
    "Please note your notebook should take no more than 10 minutes to run on lab computers. **There is 1 mark for code efficiency.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Dataset and Knowledge Preparation\n",
    "\n",
    "The provided dataset contains measurements of air quality from a multisensor device. The device used spectrometer analyzers (variables marked by \"GT\") and solid state metal oxide detectors (variables marked by \"PT08.Sx\"), as well as temperature (T), relative humidity (RH) and absolute humidity (AH) sensors. \n",
    "\n",
    "The dataset contains 3304 instances of hourly averaged measurements taken at road level in a polluted city. You will predict the CO(GT) variable representing carbon monoxide levels. There are missing features in this dataset, flagged by the number `-999`. \n",
    "\n",
    "You will need to pre-process the dataset to handle missing features, for which please self-learn from scikit-learn on how to [impute missing values](https://scikit-learn.org/stable/modules/impute.html). You will need to split the dataset into training and testing sets, also to run cross validation, when you see fit. For this, please self-learn from scikit-learn on [data splitting](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) and [cross validation](https://scikit-learn.org/stable/modules/cross_validation.html).   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CO(GT)</th>\n",
       "      <th>PT08.S1(CO)</th>\n",
       "      <th>C6H6(GT)</th>\n",
       "      <th>PT08.S2(NMHC)</th>\n",
       "      <th>NOx(GT)</th>\n",
       "      <th>PT08.S3(NOx)</th>\n",
       "      <th>NO2(GT)</th>\n",
       "      <th>PT08.S4(NO2)</th>\n",
       "      <th>PT08.S5(O3)</th>\n",
       "      <th>T</th>\n",
       "      <th>RH</th>\n",
       "      <th>AH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>1.7</td>\n",
       "      <td>973.25</td>\n",
       "      <td>5.287938</td>\n",
       "      <td>777.75</td>\n",
       "      <td>256.6</td>\n",
       "      <td>838.75</td>\n",
       "      <td>167.4</td>\n",
       "      <td>916.25</td>\n",
       "      <td>722.75</td>\n",
       "      <td>11.475000</td>\n",
       "      <td>30.075000</td>\n",
       "      <td>0.406692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1784</th>\n",
       "      <td>1.1</td>\n",
       "      <td>844.25</td>\n",
       "      <td>4.902415</td>\n",
       "      <td>758.50</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>1005.00</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>1408.75</td>\n",
       "      <td>848.00</td>\n",
       "      <td>19.475000</td>\n",
       "      <td>42.250000</td>\n",
       "      <td>0.946128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1602</th>\n",
       "      <td>3.3</td>\n",
       "      <td>1279.75</td>\n",
       "      <td>17.406491</td>\n",
       "      <td>1222.00</td>\n",
       "      <td>525.2</td>\n",
       "      <td>526.25</td>\n",
       "      <td>159.8</td>\n",
       "      <td>1519.00</td>\n",
       "      <td>1452.00</td>\n",
       "      <td>10.950000</td>\n",
       "      <td>60.950000</td>\n",
       "      <td>0.796574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>1.5</td>\n",
       "      <td>1010.25</td>\n",
       "      <td>7.640968</td>\n",
       "      <td>884.25</td>\n",
       "      <td>216.0</td>\n",
       "      <td>719.00</td>\n",
       "      <td>59.0</td>\n",
       "      <td>1430.00</td>\n",
       "      <td>938.25</td>\n",
       "      <td>16.800000</td>\n",
       "      <td>73.324999</td>\n",
       "      <td>1.391464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1557</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1093.25</td>\n",
       "      <td>10.090265</td>\n",
       "      <td>981.00</td>\n",
       "      <td>166.0</td>\n",
       "      <td>666.25</td>\n",
       "      <td>82.0</td>\n",
       "      <td>1675.50</td>\n",
       "      <td>733.25</td>\n",
       "      <td>32.650001</td>\n",
       "      <td>32.950000</td>\n",
       "      <td>1.598656</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CO(GT)  PT08.S1(CO)   C6H6(GT)  PT08.S2(NMHC)  NOx(GT)  PT08.S3(NOx)  \\\n",
       "495      1.7       973.25   5.287938         777.75    256.6        838.75   \n",
       "1784     1.1       844.25   4.902415         758.50   -999.0       1005.00   \n",
       "1602     3.3      1279.75  17.406491        1222.00    525.2        526.25   \n",
       "441      1.5      1010.25   7.640968         884.25    216.0        719.00   \n",
       "1557     2.0      1093.25  10.090265         981.00    166.0        666.25   \n",
       "\n",
       "      NO2(GT)  PT08.S4(NO2)  PT08.S5(O3)          T         RH        AH  \n",
       "495     167.4        916.25       722.75  11.475000  30.075000  0.406692  \n",
       "1784   -999.0       1408.75       848.00  19.475000  42.250000  0.946128  \n",
       "1602    159.8       1519.00      1452.00  10.950000  60.950000  0.796574  \n",
       "441      59.0       1430.00       938.25  16.800000  73.324999  1.391464  \n",
       "1557     82.0       1675.50       733.25  32.650001  32.950000  1.598656  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import sklearn.model_selection\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Import data - it should be saved in the same root directory as this notebook\n",
    "sensorDataFull = pd.read_excel('sensor_data.xlsx')\n",
    "\n",
    "# Display a sample of the data\n",
    "sensorDataFull.sample(5)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PT08.S1(CO)</th>\n",
       "      <th>C6H6(GT)</th>\n",
       "      <th>PT08.S2(NMHC)</th>\n",
       "      <th>NOx(GT)</th>\n",
       "      <th>PT08.S3(NOx)</th>\n",
       "      <th>NO2(GT)</th>\n",
       "      <th>PT08.S4(NO2)</th>\n",
       "      <th>PT08.S5(O3)</th>\n",
       "      <th>T</th>\n",
       "      <th>RH</th>\n",
       "      <th>AH</th>\n",
       "      <th>CO(GT)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>971</th>\n",
       "      <td>1392.00</td>\n",
       "      <td>24.995931</td>\n",
       "      <td>1429.00</td>\n",
       "      <td>581.0</td>\n",
       "      <td>468.50</td>\n",
       "      <td>93.0</td>\n",
       "      <td>1989.75</td>\n",
       "      <td>1494.00</td>\n",
       "      <td>16.325</td>\n",
       "      <td>75.949999</td>\n",
       "      <td>1.399074</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524</th>\n",
       "      <td>1033.25</td>\n",
       "      <td>6.981083</td>\n",
       "      <td>856.00</td>\n",
       "      <td>60.0</td>\n",
       "      <td>774.00</td>\n",
       "      <td>62.0</td>\n",
       "      <td>1735.75</td>\n",
       "      <td>768.50</td>\n",
       "      <td>27.450</td>\n",
       "      <td>59.350001</td>\n",
       "      <td>2.139496</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2832</th>\n",
       "      <td>921.00</td>\n",
       "      <td>6.969633</td>\n",
       "      <td>855.50</td>\n",
       "      <td>98.0</td>\n",
       "      <td>1163.00</td>\n",
       "      <td>93.0</td>\n",
       "      <td>1437.25</td>\n",
       "      <td>680.50</td>\n",
       "      <td>21.675</td>\n",
       "      <td>32.225000</td>\n",
       "      <td>0.825037</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>1283.25</td>\n",
       "      <td>15.012927</td>\n",
       "      <td>1149.00</td>\n",
       "      <td>585.8</td>\n",
       "      <td>587.25</td>\n",
       "      <td>235.0</td>\n",
       "      <td>1148.25</td>\n",
       "      <td>1799.25</td>\n",
       "      <td>6.325</td>\n",
       "      <td>39.424999</td>\n",
       "      <td>0.379464</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>1288.25</td>\n",
       "      <td>11.617169</td>\n",
       "      <td>1036.25</td>\n",
       "      <td>581.8</td>\n",
       "      <td>590.00</td>\n",
       "      <td>183.2</td>\n",
       "      <td>1241.50</td>\n",
       "      <td>1412.50</td>\n",
       "      <td>5.225</td>\n",
       "      <td>81.424999</td>\n",
       "      <td>0.727627</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      PT08.S1(CO)   C6H6(GT)  PT08.S2(NMHC)  NOx(GT)  PT08.S3(NOx)  NO2(GT)  \\\n",
       "971       1392.00  24.995931        1429.00    581.0        468.50     93.0   \n",
       "524       1033.25   6.981083         856.00     60.0        774.00     62.0   \n",
       "2832       921.00   6.969633         855.50     98.0       1163.00     93.0   \n",
       "191       1283.25  15.012927        1149.00    585.8        587.25    235.0   \n",
       "264       1288.25  11.617169        1036.25    581.8        590.00    183.2   \n",
       "\n",
       "      PT08.S4(NO2)  PT08.S5(O3)       T         RH        AH  CO(GT)  \n",
       "971        1989.75      1494.00  16.325  75.949999  1.399074     4.5  \n",
       "524        1735.75       768.50  27.450  59.350001  2.139496     1.4  \n",
       "2832       1437.25       680.50  21.675  32.225000  0.825037     1.0  \n",
       "191        1148.25      1799.25   6.325  39.424999  0.379464     3.7  \n",
       "264        1241.50      1412.50   5.225  81.424999  0.727627     0.4  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the features and target variable\n",
    "features = sensorDataFull.drop(columns=['CO(GT)'])  # Drop the target variable\n",
    "target = sensorDataFull['CO(GT)']\n",
    "\n",
    "# Initialize the imputer\n",
    "imputer = SimpleImputer(missing_values=-999, strategy='mean')\n",
    "\n",
    "# Fit and transform the data\n",
    "imputedFeatures = imputer.fit_transform(features)\n",
    "\n",
    "# Convert the imputed features back to a DataFrame\n",
    "imputedFeaturesDf = pd.DataFrame(imputedFeatures, columns=features.columns)\n",
    "\n",
    "# Combine the imputed features with the target variable\n",
    "imputedSensorData = pd.concat([imputedFeaturesDf, target], axis=1)\n",
    "\n",
    "# Display a sample of the imputed data\n",
    "imputedSensorData.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 182, 0, 184, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "columns = sensorDataFull.columns\n",
    "count = [len(sensorDataFull[sensorDataFull[x] == -999]) for x in columns]\n",
    "\n",
    "imputedColumns = imputedSensorData.columns\n",
    "imputedCount = [len(imputedSensorData[imputedSensorData[x] == -999]) for x in columns]\n",
    "print(str(count)+'\\n'+str(imputedCount))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample of the training set:\n",
      "       CO(GT)  PT08.S1(CO)  C6H6(GT)  PT08.S2(NMHC)  NOx(GT)  PT08.S3(NOx)  \\\n",
      "1286   924.75     6.423963    831.25           57.0   789.25          57.0   \n",
      "1049  1407.00    13.996181   1116.50          402.1   485.75         136.9   \n",
      "861    890.75     4.543700    740.00          177.3   918.75         124.1   \n",
      "1335  1014.25     6.918207    853.25           75.0   882.50          91.0   \n",
      "743    802.75     2.737271    635.25           60.0  1417.00          67.0   \n",
      "\n",
      "      NO2(GT)  PT08.S4(NO2)  PT08.S5(O3)          T        RH   AH  \n",
      "1286  1662.00        974.75       23.400  64.900001  1.842985  1.2  \n",
      "1049  1595.75       1520.50       17.725  63.324999  1.272942  3.1  \n",
      "861    787.75        502.25        9.950  25.150000  0.307917  1.2  \n",
      "1335  1538.00        974.75       16.300  57.000000  1.048352  1.3  \n",
      "743   1272.25        537.00       20.200  37.750000  0.883694  0.3  \n",
      "\n",
      "Sample of the testing set:\n",
      "      CO(GT)  PT08.S1(CO)  C6H6(GT)  PT08.S2(NMHC)  NOx(GT)  PT08.S3(NOx)  \\\n",
      "492  1024.75    10.056784    979.75     114.000000   986.25      113.0000   \n",
      "168  1300.00    13.873148   1112.50     402.100000   573.00      141.5000   \n",
      "640  1036.00     9.652147    964.50     342.000000   854.25       91.0000   \n",
      "12    930.50     2.548045    622.75      37.000000  1293.25       57.0000   \n",
      "81    742.50     1.030001    502.00     252.733536  1634.50      114.1275   \n",
      "\n",
      "     NO2(GT)  PT08.S4(NO2)  PT08.S5(O3)          T        RH   AH  \n",
      "492  1590.75        890.75       25.000  26.925000  0.840820  1.3  \n",
      "168  1291.00       1845.00       12.825  46.900001  0.691926  2.9  \n",
      "640  1544.00        986.75       19.700  57.750000  1.311183  2.2  \n",
      "12   1306.50        827.75       12.000  58.850000  0.823302  0.6  \n",
      "81   1291.50        354.50       12.700  71.650000  1.048614  0.4  \n"
     ]
    }
   ],
   "source": [
    "xTrain, xTest, yTrain, yTest = sklearn.model_selection.train_test_split(imputedFeatures, target, test_size=0.2, random_state=42)\n",
    "# Print sample of training set\n",
    "print(\"\\nSample of the training set:\")\n",
    "print(pd.DataFrame(np.concatenate((xTrain, np.array(yTrain).reshape(-1,1)), axis=1), columns=sensorDataFull.columns).sample(5))\n",
    "\n",
    "# Print sample of testing set\n",
    "print(\"\\nSample of the testing set:\")\n",
    "print(pd.DataFrame(np.concatenate((xTest, np.array(yTest).reshape(-1,1)), axis=1), columns=sensorDataFull.columns).sample(5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Linear Classification via Gradient Descent (13 marks)\n",
    "\n",
    "The air quality is assessed using the CO(GT) variable. If it is no greater than 4.5, the air quality is good (CO(GT)<=4.5), otherwise, it is bad  (CO(GT)>4.5). You will perform binary classification to predict whether the air quality is good based on the other 11 varivables, i.e., from PT08.S1(CO) to AH. \n",
    "\n",
    "### 2.1 Model Training and Testing (4 marks)\n",
    "\n",
    "This practice is about training a binary linear classifier by minimising a hinge loss with L2 (ridge) regularisation, and then testing its performance. Given a set of $N$ training samples $\\{(\\mathbf{x}_i, y_i)\\}_{i=1}^N$, where $\\mathbf{x}_i$ is the feature vector and $y_i \\in \\{-1, +1\\}$ is the class label for the $i$-th training sample, the training objective function to minimise is \n",
    "$$O = C \\sum^N_{i=1}\\max\\left(0, 1 - y_i \\left(\\mathbf{w}^T\\mathbf{x}_i + w_0\\right)\\right) + \\frac{1}{2}\\mathbf{w}^T\\mathbf{w}. $$\n",
    "Here, $\\mathbf{w}$ is a column weight vector of the linear model, $w_0$ is the bias parameter of the model, and $C$ is the regularisation hyperparameter.\n",
    "\n",
    "Recall from your lectures that gradient descent is an iterative optimisation algorithm typically used in model training. Complete the implmentation of the training function `linear_gd_train` below, which trains your linear model by minimising the above provided training objective function $O$ using gradient descent.\n",
    "\n",
    "The function should return the trained model weights and the corresponding objective function value (referred to as cost) per iteration. In addition to the training data, the function should take the regularisation hyperparameter $C$, learning rate $\\eta$, and the number of iterations $N_{max}$ as arguments. A default setting of these parameters has been provided below, which is able to provide reasonably good performance.  \n",
    "\n",
    "**Note that scikit-learn is not allowed for implementation in this section.** We recommend that you avoid using `for` loops in your implementation of the objective function or weight update, and instead use built-in numpy operations for efficiency. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_gd_train(data, labels, c=0.2, n_iters=200, learning_rate=0.001, random_state=None # Add any other arguments here if needed\n",
    "          ):\n",
    "    \"\"\"\n",
    "    A summary of your function goes here.\n",
    "\n",
    "    data: training data\n",
    "    labels: training labels (boolean)\n",
    "    c: regularisation parameter\n",
    "    n_iters: number of iterations\n",
    "    learning_rate: learning rate for gradient descent\n",
    "\n",
    "    Returns an array of cost and model weights per iteration.\n",
    "    \"\"\"\n",
    "    # Set random seed for reproducibility if using random initialisation of weights (optional)\n",
    "    rng = np.random.default_rng(seed=random_state)\n",
    "\n",
    "    # Create design matrix and labels\n",
    "    X_tilde = ...\n",
    "    y = ...\n",
    "\n",
    "    # Weight initialisation: use e.g. rng.standard_normal() or all zeros\n",
    "    w = ...\n",
    "\n",
    "    # Initialise arrays to store weights and cost at each iteration\n",
    "    w_all = ...\n",
    "    cost_all = ...\n",
    "    \n",
    "    # GD update of weights\n",
    "    for i in range(n_iters):\n",
    "        # Cost and gradient update of the linear model\n",
    "        cost = ...\n",
    "        \n",
    "        # Weight update\n",
    "        w = ...\n",
    "        \n",
    "        # save w and cost of each iteration in w_all and cost_all\n",
    "\n",
    "\n",
    "    # Return model parameters.\n",
    "    return cost_all, w_all\n",
    "\n",
    "\n",
    "def linear_predict(data, w):\n",
    "    \"\"\"\n",
    "    A summary of your function goes here.\n",
    "\n",
    "    data: test data\n",
    "    w: model weights\n",
    "\n",
    "    Returns the predicted labels.\n",
    "    \"\"\"\n",
    "\n",
    "    X_tilde = ...\n",
    "    y_pred = ...\n",
    "    \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you are ready to conduct a complete experiment of air quality classification. The provided code below splits the data into training and testing sets and imputes the missing features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sensor_data_full' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimpute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SimpleImputer\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Put a threshold on the labels to cast to binary: True if CO(GT) > 4.5, False otherwise\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m binary_targets \u001b[38;5;241m=\u001b[39m (\u001b[43msensor_data_full\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCO(GT)\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m4.5\u001b[39m)\u001b[38;5;241m.\u001b[39mto_numpy()\n\u001b[1;32m      5\u001b[0m sensor_data \u001b[38;5;241m=\u001b[39m sensor_data_full\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCO(GT)\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mto_numpy()\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Named _cls to keep our classification experiments distinct from regression\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sensor_data_full' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Put a threshold on the labels to cast to binary: True if CO(GT) > 4.5, False otherwise\n",
    "binary_targets = (sensor_data_full['CO(GT)'] > 4.5).to_numpy()\n",
    "sensor_data = sensor_data_full.drop(columns=['CO(GT)']).to_numpy()\n",
    "\n",
    "# Named _cls to keep our classification experiments distinct from regression\n",
    "train_X_cls, test_X_cls, train_y_cls, test_y_cls = sklearn.model_selection.train_test_split(sensor_data, binary_targets, test_size=0.15, stratify=binary_targets)\n",
    "\n",
    "# Impute missing values and standardise the data\n",
    "imputer = SimpleImputer(missing_values=-999, strategy='mean')\n",
    "scaler = sklearn.preprocessing.StandardScaler()\n",
    "\n",
    "train_X_cls = imputer.fit_transform(train_X_cls)\n",
    "train_X_cls = scaler.fit_transform(train_X_cls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write your code below, which should train the model, plot the training objective function value and the classification accuracy of the training set over iterations, and print the classification accuracy and $F_1$ score of the testing set. Note, use the default setting provided for $C$, $\\eta$ and $N_{max}$. Your plot should have axis labels and titles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "\n",
    "# Plot accuracy and cost per iteration on training set\n",
    "\n",
    "# Apply imputation to the test set\n",
    "\n",
    "# Predict on test set, report accuracy and f1 score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Learning Rate Analysis (3 marks)\n",
    "\n",
    "The learning rate $\\eta$ (Greek letter \"eta\") is a key parameter that affects the model training and performance. Design an appropriate experiment to demonstrate the effect of $\\eta$ on model training, and on the model performance during testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Report (6 Marks)\n",
    "Answer the following questions in your report, to be submitted separately:\n",
    "1. Derive step-by-step the gradient of the provided training objective function $O$, and the updating equation of your model weights based on gradient descent. (3 marks)\n",
    "\n",
    "2. What does the figure from section 2.1 tell you, and what is the indication of the classification accuracies of your training and testing sets? (1 mark)\n",
    "\n",
    "3. Comment on the effect of $\\eta$ on model training, and on the model performance during testing, based on your results observed in Section 2.2. (2 marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Air Quality Analysis by Neural Network (10 marks)\n",
    "\n",
    "In this experiment, you will predict the CO(GT) value based on the other 11 variables through regression. You will use a neural network to build a nonlinear regression model. Familiarise yourself with how to build a regression model by mutlilayer perceptron (MLP) using the scikit learn tutorial (https://scikit-learn.org/stable/modules/neural_networks_supervised.html#regression). \n",
    "\n",
    "\n",
    "### 3.1 Simple MLP Model Selection (4 marks)\n",
    "\n",
    "This section is focused on the practical aspects of MLP implementation and model selection. We will first compare some model architectures. \n",
    "\n",
    "The set of MLP architectures to select is specified in `param_grid` below, including two MLPs with one hidden layer, where one has a small number of 3 hidden neurons, while the other has a larger number of 100 hidden neurons, and two MLPs with two hidden layers, where one is small (3, 3) and the other is larger (100, 100). It also includes two activation function options, i.e., the logistic and the rectified linear unit (\"relu\").  These result in a total of 8 model options, where sklearn default parameters are used for all the MLPs and their training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = [\n",
    "    {   \n",
    "        'hidden_layer_sizes': [(3,), (100,), (3, 3), (100, 100)],\n",
    "        'activation': ['relu', 'logistic'],\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your code below should do the following: Split the dataset into the training and testing sets. Preprocess the data by imputing the missing features. Use the training set for model selection by cross-validation, and use mean squared error (MSE) as the model selection performance metric. You can use the scikit-learn module [GridSearchCV](https://scikit-learn.org/stable/modules/grid_search.html#grid-search) to conduct grid search. Print the cross-validation MSE with standard deviation of the selected model. Re-train the selected model using the whole training set, and print its MSE and $R^2$ score for the testing set.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redo split for regression\n",
    "\n",
    "\n",
    "# Prepare the data\n",
    "\n",
    "\n",
    "# Define MLP model\n",
    "\n",
    "\n",
    "# Initialise and fit the grid search\n",
    "\n",
    "\n",
    "# Report the best parameters and the CV results\n",
    "\n",
    "\n",
    "# Report model performance\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Training Algorithm Comparison: SGD and ADAM (2 Marks)\n",
    "\n",
    "In this exercise, you will compare two training algorithms, stochastic gradient descent (SGD) and ADAM optimisation, for training an MLP with two hidden layers each containing 100 neurons with \"relu\" activation, under the settings specified in `test_params` as below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_params = [\n",
    "    {\n",
    "        'activation': 'relu', \n",
    "        'alpha': 0.001, \n",
    "        'early_stopping': False, \n",
    "        'hidden_layer_sizes': (100, 100), \n",
    "        'solver': 'adam'\n",
    "    },{\n",
    "        'activation': 'relu', \n",
    "        'alpha': 0.001, \n",
    "        'early_stopping': False, \n",
    "        'hidden_layer_sizes': (100, 100), \n",
    "        'learning_rate': 'adaptive', \n",
    "        'momentum': 0.95, \n",
    "        'solver': 'sgd'\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the code below, where each training algorithm should run for 300 iterations (make sure to set `early_stopping=False`). For both algorithms, (1) plot the training loss (use the defaul loss setting in sklearn), as well as the MSE of both training and testing sets, over iterations; and (2) print the MSE and $R^2$ score of the trained model using the testing set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train models and plot learning curves\n",
    "\n",
    "\n",
    "# Print final test set performance for both models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Report (4 Marks)\n",
    "Answer the following questions in your report, to be submitted separately:\n",
    "1. What conclusions can you draw based on your model selection results in Section 3.1? (2 marks)\n",
    "\n",
    "2. Comment on the two training algorithms based on your results obtained in Section 3.2. (2 marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.  Build A Robust MLP Regressor (6 Marks)\n",
    "\n",
    "In this last experiment, you will develop and submit a robust MLP regressor to predict the CO(GT) value based on the other 11 variables, using the provided dataset. This robust regressor should account for the presence of missing and noisy features. \n",
    "\n",
    "Once you have developed your model, save it to a file using the provided `save_model` function for submission.\n",
    "\n",
    "### 4.1 Model Development (3 Marks)\n",
    "\n",
    "What you consider in model development should include (but not limited to) (1) handling of missing features in the unseen testing data, (2) handling of noisy features in the unseen testing data, and (3) a model selection practice.\n",
    "\n",
    "Write your model development code below. Describe briefly in your report what you have considered in your model development.\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "### OPTIONAL: move completed model selection code to this 'raw' cell below before final submission \n",
    "# You can run your code once to select the best hyperparameters and train your model, then\n",
    "# move the code to this cell for submission. This prevents it from executing automatically and so\n",
    "# excludes time-consuming hyperparameter selection from total notebook run time during marking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 External Testing (3 Marks)\n",
    "Save your trained model for submission, and submit it along with your notebook and report. It will be run and evaluated on a test set unseen by you.\n",
    "\n",
    "**Important: set your university username (e.g. mbxxabc3) below when saving your model.** Failure to do this correctly would lead to your model not being marked!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import model_eval_utils\n",
    "\n",
    "#### SAVE YOUR MODEL\n",
    "student_username = \"mbxxxxx0\" # SET YOUR USERNAME HERE\n",
    "model = ... # SET YOUR MODEL HERE\n",
    "model_eval_utils.save_model(student_username, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total notebook run time: 304 seconds\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total notebook run time: {time.time() - notebook_start_time:.0f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option to test your saved model\n",
    "Use the `run_model()` function to make sure your saved model can be loaded and run before submitting.\n",
    "\n",
    "Please note the score returned by `run_model()` is not in any way indicative of your final mark. This is just a simple test to make sure your model can be loaded and run. When testing your model, the GTA will run your model following the practice below, but replacing the bunk_data with the testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to load from ....\n",
      "Loaded ./mbxxxxx0.sav model.\n",
      "Could not score model. Attempting predictions...\n",
      "Model failed to predict.\n"
     ]
    }
   ],
   "source": [
    "# some bunk data\n",
    "bunk_data = np.array([[ 1.22400000e+03,  9.97440117e+00,\n",
    "        9.76666667e+02,  2.50600000e+02,  5.71333333e+02,\n",
    "        1.30700000e+02,  1.42433333e+03,  1.00166667e+03,\n",
    "        2.32666664e+01,  3.57999992e+01,  1.00855762e+00],\n",
    "    [ 9.24250000e+02,   3.97337806e+00,\n",
    "        7.09250000e+02,  6.30000000e+01,  1.15800000e+03,\n",
    "        7.50000000e+01,  1.31800000e+03,  6.09750000e+02,\n",
    "        1.60500000e+01,  4.13500004e+01,  7.48680717e-01],\n",
    "    [ 8.92000000e+02,  5.06611560e+00,\n",
    "        7.66750000e+02,  7.10000000e+01,  1.18000000e+03,\n",
    "        8.40000000e+01,  1.46600000e+03,  6.56750000e+02,\n",
    "        1.79749999e+01,  5.14499998e+01,  1.05039283e+00]])\n",
    "bunk_labels = np.array([2. , 1.3, 6.1])\n",
    "\n",
    "score = model_eval_utils.run_model(student_username, \n",
    "                                test_data=bunk_data, \n",
    "                                test_labels=bunk_labels, \n",
    "                                model_folder=\".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
